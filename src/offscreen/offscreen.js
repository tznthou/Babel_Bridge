/**
 * Offscreen Document - è™•ç†éŸ³è¨Šæ“·å–ã€åˆ‡å¡Šå’Œ MP3 ç·¨ç¢¼
 *
 * Manifest V3 é™åˆ¶ï¼š
 * - Service Worker ä¸æ”¯æ´ AudioContextã€MediaStreamã€Web Worker
 * - å¿…é ˆåœ¨ Offscreen Document ä¸­è™•ç†æ‰€æœ‰éŸ³è¨Šç›¸é—œæ“ä½œ
 *
 * åŠŸèƒ½ï¼š
 * 1. ä½¿ç”¨ streamId å–å¾— MediaStream
 * 2. å»ºç«‹ AudioContext è™•ç†éŸ³è¨Š
 * 3. éŸ³è¨Šåˆ‡å¡Š (Rolling Window)
 * 4. MP3 ç·¨ç¢¼ (via Worker)
 * 5. ç™¼é€è™•ç†çµæœå› Service Worker
 *
 * é€šè¨Šæµç¨‹:
 * Service Worker â†’ getMediaStreamId() â†’ streamId
 * â†’ Offscreen Document â†’ getUserMedia() â†’ MediaStream
 * â†’ AudioContext â†’ AudioChunker â†’ MP3 Worker â†’ MP3 blob
 * â†’ Service Worker â†’ Whisper API
 */

// === MP3 Worker ç®¡ç† ===
let mp3Worker = null;
let pendingRequests = new Map();
let requestIdCounter = 0;

// === éŸ³è¨Šæ“·å–ç‹€æ…‹ ===
let audioContext = null;
let mediaStream = null;
let sourceNode = null;
let processorNode = null;

// === éŸ³è¨Šåˆ‡å¡Šç‹€æ…‹ ===
let chunkBuffer = [];
let chunkIndex = 0;
let totalSamples = 0;
let isProcessingChunk = false; // ğŸ”’ é˜²æ­¢ä¸¦ç™¼è™•ç†

// === é…ç½® (æš«æ™‚ç¡¬ç·¨ç¢¼ï¼Œä¹‹å¾Œæ‡‰å¾ config.js å°å…¥) ===
const AUDIO_CONFIG = {
  SAMPLE_RATE: 16000,
  CHANNELS: 1,
};

const CHUNK_CONFIG = {
  CHUNK_DURATION: 3, // 3 ç§’
  OVERLAP_DURATION: 1, // 1 ç§’é‡ç–Š
  MIN_CHUNK_DURATION: 0.5, // æœ€å° chunk é•·åº¦
};

/**
 * åˆå§‹åŒ– MP3 Encoder Worker
 */
function initWorker() {
  if (mp3Worker) {
    return;
  }

  // å‰µå»º Workerï¼ˆOffscreen Document æ”¯æ´ï¼‰
  mp3Worker = new Worker('/src/workers/mp3-encoder.worker.js', { type: 'module' });

  // ç›£è½ Worker è¨Šæ¯
  mp3Worker.onmessage = (event) => {
    const { requestId, type, data, error } = event.data;

    const pending = pendingRequests.get(requestId);
    if (!pending) {
      console.warn('[Offscreen] æ”¶åˆ°æœªçŸ¥ requestId çš„å›æ‡‰:', requestId);
      return;
    }

    pendingRequests.delete(requestId);

    if (type === 'ENCODE_COMPLETE') {
      pending.resolve(data);
    } else if (type === 'ENCODE_ERROR') {
      pending.reject(new Error(error));
    }
  };

  mp3Worker.onerror = (error) => {
    console.error('[Offscreen] Worker éŒ¯èª¤:', error);

    // æ‹’çµ•æ‰€æœ‰å¾…è™•ç†çš„è«‹æ±‚
    for (const [requestId, pending] of pendingRequests.entries()) {
      pending.reject(new Error('Worker crashed'));
      pendingRequests.delete(requestId);
    }
  };

  console.log('[Offscreen] MP3 Worker å·²åˆå§‹åŒ–');
}

/**
 * è™•ç†ä¾†è‡ª Service Worker çš„è¨Šæ¯
 */
chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
  const { type, data } = message;

  console.log('[Offscreen] æ”¶åˆ°è¨Šæ¯:', type);

  switch (type) {
    case 'OFFSCREEN_INIT_WORKER':
      handleInitWorker(sendResponse);
      return true; // ç•°æ­¥å›æ‡‰

    case 'OFFSCREEN_START_AUDIO_CAPTURE':
      handleStartAudioCapture(data, sendResponse);
      return true; // ç•°æ­¥å›æ‡‰

    case 'OFFSCREEN_STOP_AUDIO_CAPTURE':
      handleStopAudioCapture(sendResponse);
      return true; // ç•°æ­¥å›æ‡‰

    case 'OFFSCREEN_ENCODE_MP3':
      handleEncodeMp3(data, sendResponse);
      return true; // ç•°æ­¥å›æ‡‰

    case 'OFFSCREEN_TERMINATE_WORKER':
      handleTerminateWorker(sendResponse);
      return true; // ç•°æ­¥å›æ‡‰

    default:
      console.warn('[Offscreen] æœªçŸ¥è¨Šæ¯é¡å‹:', type);
      sendResponse({ success: false, error: 'Unknown message type' });
      return false;
  }
});

/**
 * è™•ç† Worker åˆå§‹åŒ–è«‹æ±‚
 */
function handleInitWorker(sendResponse) {
  try {
    initWorker();
    sendResponse({ success: true });
  } catch (error) {
    console.error('[Offscreen] Worker åˆå§‹åŒ–å¤±æ•—:', error);
    sendResponse({ success: false, error: error.message });
  }
}

/**
 * è™•ç† MP3 ç·¨ç¢¼è«‹æ±‚
 */
async function handleEncodeMp3(encodingData, sendResponse) {
  try {
    if (!mp3Worker) {
      initWorker();
    }

    // ç”Ÿæˆå”¯ä¸€çš„è«‹æ±‚ ID
    const requestId = requestIdCounter++;

    // å‰µå»º Promise ç­‰å¾… Worker å›æ‡‰
    const resultPromise = new Promise((resolve, reject) => {
      pendingRequests.set(requestId, { resolve, reject });
    });

    // ç™¼é€ç·¨ç¢¼è«‹æ±‚åˆ° Worker
    mp3Worker.postMessage({
      type: 'ENCODE',
      requestId,
      data: encodingData
    });

    // ç­‰å¾…çµæœ
    const result = await resultPromise;

    sendResponse({ success: true, data: result });
  } catch (error) {
    console.error('[Offscreen] MP3 ç·¨ç¢¼å¤±æ•—:', error);
    sendResponse({ success: false, error: error.message });
  }
}

/**
 * è™•ç† Worker çµ‚æ­¢è«‹æ±‚
 */
function handleTerminateWorker(sendResponse) {
  try {
    if (mp3Worker) {
      mp3Worker.terminate();
      mp3Worker = null;
      pendingRequests.clear();
      console.log('[Offscreen] Worker å·²çµ‚æ­¢');
    }
    sendResponse({ success: true });
  } catch (error) {
    console.error('[Offscreen] Worker çµ‚æ­¢å¤±æ•—:', error);
    sendResponse({ success: false, error: error.message });
  }
}

/**
 * è™•ç†éŸ³è¨Šæ“·å–é–‹å§‹è«‹æ±‚
 */
async function handleStartAudioCapture(captureData, sendResponse) {
  try {
    const { streamId, tabId } = captureData;

    console.log(`[Offscreen] é–‹å§‹éŸ³è¨Šæ“·å–ï¼ŒstreamId: ${streamId}, tabId: ${tabId}`);

    // åœæ­¢ç¾æœ‰çš„æ“·å–ï¼ˆå¦‚æœæœ‰ï¼‰
    stopAudioCapture();

    // Step 1: ä½¿ç”¨ streamId å–å¾— MediaStream
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        mandatory: {
          chromeMediaSource: 'tab',
          chromeMediaSourceId: streamId,
        },
      },
    });

    console.log('[Offscreen] MediaStream å·²å–å¾—');

    // Step 2: å»ºç«‹ AudioContext
    audioContext = new AudioContext({
      sampleRate: AUDIO_CONFIG.SAMPLE_RATE,
    });

    // ç¢ºä¿ AudioContext è™•æ–¼ running ç‹€æ…‹ï¼ˆé¿å…è¢« autoplay policy æš«åœï¼‰
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
      console.log('[Offscreen] AudioContext å·²å¾æš«åœç‹€æ…‹æ¢å¾©');
    }

    console.log(`[Offscreen] AudioContext å·²å»ºç«‹ï¼Œstate: ${audioContext.state}, sample rate: ${audioContext.sampleRate}`);

    // Step 3: å»ºç«‹éŸ³è¨Šè™•ç†ç¯€é»
    sourceNode = audioContext.createMediaStreamSource(mediaStream);

    // ä½¿ç”¨ ScriptProcessorNode è™•ç†éŸ³è¨Š (bufferSize: 4096)
    processorNode = audioContext.createScriptProcessor(4096, 1, 1);

    // è¨ˆç®—åˆ‡å¡Šåƒæ•¸
    const chunkSamples = AUDIO_CONFIG.SAMPLE_RATE * CHUNK_CONFIG.CHUNK_DURATION;
    const overlapSamples = AUDIO_CONFIG.SAMPLE_RATE * CHUNK_CONFIG.OVERLAP_DURATION;
    const stepSamples = chunkSamples - overlapSamples;

    console.log('[Offscreen] éŸ³è¨Šåˆ‡å¡Šåƒæ•¸', {
      chunkSamples,
      overlapSamples,
      stepSamples,
    });

    // Step 4: è™•ç†éŸ³è¨Šè³‡æ–™
    processorNode.onaudioprocess = (event) => {
      const channelData = event.inputBuffer.getChannelData(0);

      // ğŸš€ æ•ˆèƒ½å„ªåŒ–ï¼šä½¿ç”¨å¾ªç’°æ›¿ä»£ spread operatorï¼Œé¿å…å †ç–Šæº¢å‡º
      // åŸæœ¬çš„ push(...channelData) æ¯æ¬¡å±•é–‹ 4096 å€‹å…ƒç´ ï¼Œé€ æˆ GC å£“åŠ›
      for (let i = 0; i < channelData.length; i++) {
        chunkBuffer.push(channelData[i]);
      }
      totalSamples += channelData.length;

      // ğŸ”’ éé˜»å¡è™•ç†ï¼šåªåœ¨æ²’æœ‰æ­£åœ¨è™•ç†çš„ chunk æ™‚è§¸ç™¼
      if (!isProcessingChunk && chunkBuffer.length >= chunkSamples) {
        processNextChunk(chunkSamples, overlapSamples, stepSamples);
      }
    };

    // é€£æ¥ç¯€é»
    sourceNode.connect(processorNode);
    processorNode.connect(audioContext.destination);

    console.log('[Offscreen] éŸ³è¨Šè™•ç†ç®¡ç·šå·²å»ºç«‹');

    sendResponse({ success: true });
  } catch (error) {
    console.error('[Offscreen] éŸ³è¨Šæ“·å–å¤±æ•—:', error);
    stopAudioCapture();
    sendResponse({ success: false, error: error.message });
  }
}

/**
 * éé˜»å¡è™•ç†ä¸‹ä¸€å€‹ chunk
 */
async function processNextChunk(chunkSamples, overlapSamples, stepSamples) {
  isProcessingChunk = true;

  try {
    // è™•ç†æ‰€æœ‰ç´¯ç©çš„ chunksï¼ˆä½†ä¸é˜»å¡ onaudioprocessï¼‰
    while (chunkBuffer.length >= chunkSamples) {
      await extractAndEncodeChunk(chunkSamples, overlapSamples, stepSamples);
    }
  } finally {
    isProcessingChunk = false;
  }
}

/**
 * å¾ç·©è¡å€æå–ä¸€å€‹ chunk ä¸¦ç·¨ç¢¼ç‚º MP3
 */
async function extractAndEncodeChunk(chunkSamples, overlapSamples, stepSamples) {
  // å–å‡º chunk
  const samples = chunkBuffer.slice(0, chunkSamples);

  // è¨ˆç®—æ™‚é–“æˆ³
  const startTime = chunkIndex * (stepSamples / AUDIO_CONFIG.SAMPLE_RATE);
  const endTime = startTime + CHUNK_CONFIG.CHUNK_DURATION;

  console.log(`[Offscreen] æå– Chunk ${chunkIndex}`, {
    startTime: startTime.toFixed(2),
    endTime: endTime.toFixed(2),
    samples: samples.length,
  });

  try {
    // åˆå§‹åŒ– Worker (å¦‚æœéœ€è¦)
    if (!mp3Worker) {
      initWorker();
    }

    // ç·¨ç¢¼ç‚º MP3
    const requestId = requestIdCounter++;
    const resultPromise = new Promise((resolve, reject) => {
      pendingRequests.set(requestId, { resolve, reject });
    });

    mp3Worker.postMessage({
      type: 'ENCODE',
      requestId,
      data: {
        samples: new Float32Array(samples),
        sampleRate: AUDIO_CONFIG.SAMPLE_RATE,
      },
    });

    const result = await resultPromise;

    console.log(`[Offscreen] Chunk ${chunkIndex} ç·¨ç¢¼å®Œæˆï¼Œå¤§å°: ${result.size} bytes`);

    // ç™¼é€ç·¨ç¢¼çµæœçµ¦ Service Worker
    chrome.runtime.sendMessage({
      type: 'AUDIO_CHUNK_READY',
      data: {
        chunkIndex,
        startTime,
        endTime,
        blob: result.blob,
        size: result.size,
        duration: result.duration,
      },
    });

    // ç§»é™¤å·²è™•ç†çš„æ¨£æœ¬ (ä¿ç•™é‡ç–Šéƒ¨åˆ†)
    chunkBuffer.splice(0, stepSamples);
    chunkIndex++;
  } catch (error) {
    console.error(`[Offscreen] Chunk ${chunkIndex} ç·¨ç¢¼å¤±æ•—:`, error);
    // ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹ chunk
  }
}

/**
 * è™•ç†éŸ³è¨Šæ“·å–åœæ­¢è«‹æ±‚
 */
function handleStopAudioCapture(sendResponse) {
  try {
    stopAudioCapture();
    sendResponse({ success: true });
  } catch (error) {
    console.error('[Offscreen] åœæ­¢éŸ³è¨Šæ“·å–å¤±æ•—:', error);
    sendResponse({ success: false, error: error.message });
  }
}

/**
 * åœæ­¢éŸ³è¨Šæ“·å–ä¸¦æ¸…ç†è³‡æº
 */
function stopAudioCapture() {
  console.log('[Offscreen] åœæ­¢éŸ³è¨Šæ“·å–');

  // æ–·é–‹éŸ³è¨Šç¯€é»
  if (processorNode) {
    processorNode.disconnect();
    processorNode.onaudioprocess = null;
    processorNode = null;
  }

  if (sourceNode) {
    sourceNode.disconnect();
    sourceNode = null;
  }

  // åœæ­¢ MediaStream
  if (mediaStream) {
    mediaStream.getTracks().forEach((track) => track.stop());
    mediaStream = null;
  }

  // é—œé–‰ AudioContext
  if (audioContext && audioContext.state !== 'closed') {
    audioContext.close();
    audioContext = null;
  }

  // é‡è¨­ç‹€æ…‹
  chunkBuffer = [];
  chunkIndex = 0;
  totalSamples = 0;
  isProcessingChunk = false;
}

console.log('[Offscreen] Offscreen document å·²è¼‰å…¥');
